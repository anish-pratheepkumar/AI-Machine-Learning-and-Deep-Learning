{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using a pretrained cnn - VGG16 (trained on imagenet data set of animals) \n",
    "#this is available as an application in keras\n",
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',                          #this argument is weight initialisation we can use either the imagenet weights or random initialisation\n",
    "            include_top=False,                                 #False => not to use the dense layers \n",
    "            input_shape=(150, 150, 3))\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#defining direcory location for the image input to the network, no need to use os.mkdir here since directory is already made before\n",
    "base_dir = '/home/anish/Documents/Jupyter Notebook/SA-DLwithPy/CatsVsDogs/cats_and_dogs_small'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#designing the network architecture with the conv base as first layer and then adding dense classifier to it\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "#freezing the conv base weights so that it is not modified while feeding the data through it\n",
    "print('This is the number of trainable weights '\n",
    "      'before freezing the conv base:', len(model.trainable_weights))\n",
    "\n",
    "conv_base.trainable = False\n",
    "\n",
    "print('This is the number of trainable weights '\n",
    "      'after freezing the conv base:', len(model.trainable_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model end to end with the frozen conv base and augmented data i/p to the network\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "\n",
    "#augmenting data using imagedatagenerator class of keras\n",
    "train_datagen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                rotation_range=40,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                horizontal_flip=True,\n",
    "                fill_mode='nearest')\n",
    "#validation data is not augmented only rescaled to values btwn 0 and 1 for easy processing of the data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#generator fot train data\n",
    "train_generator = train_datagen.flow_from_directory(            #using flow from directory method of imagedatagenerator class to generate datas\n",
    "                  train_dir,                                    #specifying directory from which data is to be loaded\n",
    "                  target_size=(150, 150),                       #resizing the image\n",
    "                  batch_size=20,\n",
    "                  class_mode='binary')\n",
    "\n",
    "#generator fot validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "                       validation_dir,\n",
    "                       target_size=(150, 150),\n",
    "                       batch_size=20,\n",
    "                       class_mode='binary')\n",
    "\n",
    "#compiling the designed model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "             metrics=['acc'])\n",
    "\n",
    "#fitting the generated augmented images to the corresponding labels by using the compiled model \n",
    "history = model.fit_generator( \n",
    "          train_generator,                                #generating the train data\n",
    "          steps_per_epoch=100,                            #breaking the data generation and now its time for weight updates, this marks one epoch\n",
    "          epochs=30,\n",
    "          validation_data=validation_generator,\n",
    "          validation_steps=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the results - training (accuracy and losses) vs validation (accuracy and losses)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finetuning - training by unfreezing only few top layers of conv base\n",
    "conv_base.trainable = True                                #unfreezing the whole convnet\n",
    "\n",
    "set_trainable = False                                    #initialising a boolean variable\n",
    "\n",
    "for layer in conv_base.layers:                           #iterating over layers in conv net\n",
    "    if layer.name == 'block5_conv1':                     #if layer name is block5 then making those layers trainable\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False     \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the model with a very low learning rate : so that the trainable weights\n",
    "#of the convnet is not modified too much, which might harm the representations it is having\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-5),     #learning rate is set low        \n",
    "              metrics=['acc'])\n",
    "\n",
    "#fitting the model with generated augmented i/p images and its labels using the \n",
    "#model with top few conv layer set to trainable\n",
    "history = model.fit_generator(\n",
    "          train_generator,                              #loading train data from this directory\n",
    "          steps_per_epoch=100,                          #breaking the data generation, with this one epoch is completed and the trainable weights are updated\n",
    "          epochs=100,\n",
    "          validation_data=validation_generator,         #loading the unaugmented validation data\n",
    "          validation_steps=50)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the results after unfreezing top 3 layers of pretrained convnet - training (accuracy and losses) vs validation (accuracy and losses)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smoothening the curves\n",
    "def smooth_curve(points, factor=0.8):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points\n",
    "\n",
    "plt.plot(epochs,smooth_curve(acc), 'bo', label='Smoothed training acc')\n",
    "plt.plot(epochs,smooth_curve(val_acc), 'b', label='Smoothed validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs,smooth_curve(loss), 'bo', label='Smoothed training loss')\n",
    "plt.plot(epochs,smooth_curve(val_loss), 'b', label='Smoothed validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluating the model for the test data\n",
    "#generating test data\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                 test_dir,\n",
    "                 target_size=(150, 150),\n",
    "                 batch_size=20,\n",
    "                 class_mode='binary')\n",
    "#evaluating the result of the test data on the trained model\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
    "\n",
    "print('test acc:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
