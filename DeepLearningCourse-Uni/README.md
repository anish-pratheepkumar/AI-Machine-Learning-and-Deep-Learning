# Deep Learning - Course by Prof MÃ¼ller
The exercises are based on the Deep Learning framework - Pytorch. Starting with introduction to python the exercises moves to implementing forward and backward propagation from scratch and in the end training MNIST and CIFAR10 data sets using CNN.

### Exercise_1 [_Intro_Python&NumPy](https://github.com/anish-pratheepkumar/GitDeepLearningStudy/tree/master/DeepLearningCourse-Uni/Exercise_1_Intro_Python%26NumPy)

This exercise focuses on familiarising the Python programming language and also understanding NumPy library.

### Exercise_2[_WineRegression](https://github.com/anish-pratheepkumar/GitDeepLearningStudy/tree/master/DeepLearningCourse-Uni/Exercise_2_WineRegression)

A regression problem is solved using wine data(3674 training data) in a .csv file, having 10 features of the wine and corresponding quality. Here a regression model is developed which can predict the quality of the wine when given the 10 input features.

### Exercise_3[_forward from scratch](https://github.com/anish-pratheepkumar/GitDeepLearningStudy/tree/master/DeepLearningCourse-Uni/Exercise_3_forward%20from%20scratch)

Here the forward propagation concept in Neural Network is implemented from scratch using Python.

### Exercise_4

Next the back propagation is implemented from scratch using Python. This is similar to Autograd in Pytorch.

### Exercise_5

The Stochastic Gradient Descent(SGD) optimisation is implemented from scratch. Also an introduction to PYtorch is given in this Exercise.

### Exercise_6

First section gives information regarding the parameter initialisation of a Network. Followed by implementation of Batch Normalisation.

### Exercise_7

The Dropout regularisation is implemented using Python.

### Exercise_8.0

The Convolutional Neural Network implemnetation using Python and also a look at the edge detector and Gaussian Filter.

### Exercise_8.1

The MNIST and CIFAR10 datasets are trained using Pytorch framework and the results are presented.

### Exercise_8.2

The concept of replacing the Fully Conected Layers (at the end of a CNN) to  Convlutional layers is implemented here. 





