{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural networks [6 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the pre-defined network ``MNISTNet`` defined below on the MNIST dataset. You have to get an accuracy of at least 95% on a hidden test set. Use the loader from below as data loader of the trainig set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "\n",
    "dataset = MNIST('data', download=True, transform=transforms.ToTensor())\n",
    "loader = DataLoader(dataset, batch_size=16, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "<class 'tuple'>\n",
      "torch.Size([1, 28, 28])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset)) #this is only training set\n",
    "\n",
    "el = dataset[3]                 #el is a tuple containing 2 list 1 image 2 its labels\n",
    "print(type(el))\n",
    "print(el[0].shape)                #image is again a sub list inside el so it is [1,28,28] so calling el[0][0] accesses the sblist image first then the 1st element inside the image this has now size 28x28\n",
    "print(el[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 28, 28])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "batch = iter(loader).next()   #batch is an iterator which gives a single list at a time. each list has 2 elements, element 0 is a list of 4 images and element 1 is a list of its labels\n",
    "\n",
    "data = batch[0]                     #this image is a 3D tensor => CxWxH which means image is again a list inside list\n",
    "labels = batch[1]\n",
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Label: 1')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAOeklEQVR4nO3dfYwc9X3H8c/HxNStg8DGrTFPdoJQJRRRp7JopJ5aV3Fcg4ggf9SKpbRGobn8EWgjhcqIUgFtI6HSJHUpRLoI/EBSUlRDjKgVQi0eWlmkHNQBA3aglh18su+gBGG3kQjct3/sOD3M7ex5Z2dnfd/3S1rd7vxmZ743us/95mF3fo4IAZj95jRdAID+IOxAEoQdSIKwA0kQdiAJwg4kQdgTs/2E7T/u93vRDMI+C9g+YHtV03W0Y/tjth+1/YZtPtjREMKOfvi5pAckXdt0IZkR9lnM9gLbj9h+3fZPi+fnnzDbRbb/w/bbtrfbXjjl/Z+wvcv2W7Z/ZHtlN3VExL6IuEfSixV+HVRE2Ge3OZI2SVoq6UJJP5P0DyfM80eSPi9piaR3Jf29JNk+T9K/SPprSQsl3SBpm+1fPXElti8s/iFcWNPvgR4g7LNYRPx3RGyLiP+NiKOSvirpd0+Y7b6I2BMR/yPpLySttX2apM9J2hEROyJiMiIekzQq6Ypp1vOTiDgrIn5S86+ECj7UdAGoj+1fkfQNSWskLSgmn2H7tIh4r3j92pS3HJQ0V9IitfYG/sD2p6e0z5X0eL1Voy6EfXb7iqRfl/RbEXHE9nJJ/ynJU+a5YMrzC9U6mfaGWv8E7ouIL/SrWNSL3fjZY67teVMeH5J0hlrH6W8VJ95umeZ9n7N9SbEX8JeS/rno9b8t6dO2f9/2acUyV05zgq8jt8yTdHrxep7tX+r2F0V3CPvssUOtYB9/3Crp7yT9slo99dOSvj/N++6TtFnSEUnzJP2JJEXEa5KuknSTpNfV6un/TNP8zRQn6I6VnKBbWtR0/Gz8zyTtO8nfDxWZm1cAOdCzA0kQdiAJwg4kQdiBJPp6nZ1vPAH1iwhPN71Sz257je19tl+1fWOVZQGoV9eX3orPT/9Y0qckHZL0jKR1EfFSyXvo2YGa1dGzXybp1YjYHxHvSPquWh/CADCAqoT9PL3/SxSHimnvY3vY9qjt0QrrAlBR7SfoImJE0ojEbjzQpCo9+5je/42p84tpAAZQlbA/I+li2x+xfbqkz0p6uDdlAei1rnfjI+Jd29dJelTSaZLujQjuMQYMqL5+641jdqB+tXyoBsCpg7ADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkuh6yGajbzTffXNp+2223lbbPmdO+L1u5cmXpe5988snS9lNRpbDbPiDpqKT3JL0bESt6URSA3utFz/57EfFGD5YDoEYcswNJVA17SPqB7WdtD083g+1h26O2RyuuC0AFVXfjhyJizPavSXrM9t6IeGrqDBExImlEkmxHxfUB6FKlnj0ixoqfE5IeknRZL4oC0Htdh932fNtnHH8uabWkPb0qDEBvVdmNXyzpIdvHl/OPEfH9nlSFFK655prS9g0bNpS2T05Odr3uiHxHlF2HPSL2S/qNHtYCoEZcegOSIOxAEoQdSIKwA0kQdiAJvuKKxixdurS0fd68eX2qJAd6diAJwg4kQdiBJAg7kARhB5Ig7EAShB1IguvsqNWqVavatl1//fWVlr13797S9iuvvLJt2/j4eKV1n4ro2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCa6zo5KhoaHS9k2bNrVtO/PMMyut+4477ihtP3jwYKXlzzb07EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBNfZUcn69etL288999yul/3EE0+Utm/durXrZWfUsWe3fa/tCdt7pkxbaPsx268UPxfUWyaAqmayG79Z0poTpt0oaWdEXCxpZ/EawADrGPaIeErSmydMvkrSluL5FklX97guAD3W7TH74og4XDw/ImlxuxltD0sa7nI9AHqk8gm6iAjbUdI+ImlEksrmA1Cvbi+9jdteIknFz4nelQSgDt2G/WFJx6+5rJe0vTflAKiLI8r3rG3fL2mlpEWSxiXdIul7kh6QdKGkg5LWRsSJJ/GmWxa78aeYRYsWlbZ3uv/65ORk27a33nqr9L1r164tbX/88cdL27OKCE83veMxe0Ssa9P0yUoVAegrPi4LJEHYgSQIO5AEYQeSIOxAEnzFNblly5aVtm/btq22dd95552l7Vxa6y16diAJwg4kQdiBJAg7kARhB5Ig7EAShB1Iguvsya1Zc+K9RN/v0ksvrbT8nTt3tm3buHFjpWXj5NCzA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASHW8l3dOVcSvpvrv66vJh+DZv3lzaPn/+/NL2Xbt2lbaX3Q66022o0Z12t5KmZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJPg++yxQdu/3Ou/7Lkn79+8vbeda+uDo2LPbvtf2hO09U6bdanvM9u7icUW9ZQKoaia78ZslTXc7k29ExPLisaO3ZQHotY5hj4inJL3Zh1oA1KjKCbrrbD9f7OYvaDeT7WHbo7ZHK6wLQEXdhv2bki6StFzSYUlfazdjRIxExIqIWNHlugD0QFdhj4jxiHgvIiYlfUvSZb0tC0CvdRV220umvPyMpD3t5gUwGDpeZ7d9v6SVkhbZPiTpFkkrbS+XFJIOSPpijTWigw0bNrRtm5ycrHXdt99+e63LR+90DHtErJtm8j011AKgRnxcFkiCsANJEHYgCcIOJEHYgST4iuspYPny5aXtq1evrm3d27dvL23ft29fbetGb9GzA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASDNl8CpiYmChtX7Cg7V3BOnr66adL2y+//PLS9mPHjnW9btSDIZuB5Ag7kARhB5Ig7EAShB1IgrADSRB2IAm+z34KOPvss0vbq9wu+u677y5t5zr67EHPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJzGTI5gskbZW0WK0hmkciYqPthZL+SdIytYZtXhsRP62v1Nlr06ZNpe1z5tT3P3nXrl21LRuDZSZ/Re9K+kpEXCLpE5K+ZPsSSTdK2hkRF0vaWbwGMKA6hj0iDkfEc8Xzo5JelnSepKskbSlm2yLp6rqKBFDdSe0f2l4m6eOSfihpcUQcLpqOqLWbD2BAzfiz8bY/LGmbpC9HxNv2/9/mKiKi3f3lbA9LGq5aKIBqZtSz256rVtC/ExEPFpPHbS8p2pdImvauiBExEhErImJFLwoG0J2OYXerC79H0ssR8fUpTQ9LWl88Xy+pfLhPAI2ayW78b0v6Q0kv2N5dTLtJ0u2SHrB9raSDktbWU+Kpr9OQy6tWrSpt7/QV1nfeeadt21133VX63vHx8dJ2zB4dwx4R/y5p2vtQS/pkb8sBUBc+QQckQdiBJAg7kARhB5Ig7EAShB1IgltJ98FZZ51V2n7OOedUWv7Y2FjbthtuuKHSsjF70LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEnyfvQ/27t1b2t5p2OShoaFeloOk6NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAlHRPkM9gWStkpaLCkkjUTERtu3SvqCpNeLWW+KiB0dllW+MgCVRcS0Q6zPJOxLJC2JiOdsnyHpWUlXS1or6VhE/O1MiyDsQP3ahb3jJ+gi4rCkw8Xzo7ZflnReb8sDULeTOma3vUzSxyX9sJh0ne3nbd9re0Gb9wzbHrU9WqlSAJV03I3/xYz2hyU9KemrEfGg7cWS3lDrOP6v1NrV/3yHZbAbD9Ss62N2SbI9V9Ijkh6NiK9P075M0iMR8bEOyyHsQM3ahb3jbrxtS7pH0stTg16cuDvuM5L2VC0SQH1mcjZ+SNK/SXpB0mQx+SZJ6yQtV2s3/oCkLxYn88qWRc8O1KzSbnyvEHagfl3vxgOYHQg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ9HvI5jckHZzyelExbRANam2DWpdEbd3qZW1L2zX09fvsH1i5PRoRKxoroMSg1jaodUnU1q1+1cZuPJAEYQeSaDrsIw2vv8yg1jaodUnU1q2+1NboMTuA/mm6ZwfQJ4QdSKKRsNteY3uf7Vdt39hEDe3YPmD7Bdu7mx6frhhDb8L2ninTFtp+zPYrxc9px9hrqLZbbY8V22637Ssaqu0C24/bfsn2i7b/tJje6LYrqasv263vx+y2T5P0Y0mfknRI0jOS1kXES30tpA3bByStiIjGP4Bh+3ckHZO09fjQWrb/RtKbEXF78Y9yQURsGJDabtVJDuNdU23thhm/Rg1uu14Of96NJnr2yyS9GhH7I+IdSd+VdFUDdQy8iHhK0psnTL5K0pbi+Ra1/lj6rk1tAyEiDkfEc8Xzo5KODzPe6LYrqasvmgj7eZJem/L6kAZrvPeQ9APbz9oebrqYaSyeMszWEUmLmyxmGh2H8e6nE4YZH5ht183w51Vxgu6DhiLiNyVdLulLxe7qQIrWMdggXTv9pqSL1BoD8LCkrzVZTDHM+DZJX46It6e2NbntpqmrL9utibCPSbpgyuvzi2kDISLGip8Tkh5S67BjkIwfH0G3+DnRcD2/EBHjEfFeRExK+pYa3HbFMOPbJH0nIh4sJje+7aarq1/brYmwPyPpYtsfsX26pM9KeriBOj7A9vzixIlsz5e0WoM3FPXDktYXz9dL2t5gLe8zKMN4txtmXA1vu8aHP4+Ivj8kXaHWGfn/kvTnTdTQpq6PSvpR8Xix6dok3a/Wbt3P1Tq3ca2ksyXtlPSKpH+VtHCAartPraG9n1crWEsaqm1IrV305yXtLh5XNL3tSurqy3bj47JAEpygA5Ig7EAShB1IgrADSRB2IAnCDiRB2IEk/g/81XnivPfTBQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(el[0][0], cmap='gray', vmin=0., vmax=1.)   #calls 1st element of tuple, the image. then the 1st channel of the image\n",
    "plt.title('Label: {}'.format(el[1]))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.first_layer = nn.Sequential(nn.Conv2d(1, 16, 3, padding=1), nn.ReLU())\n",
    "        self.conv_layers = nn.Sequential(*[nn.Sequential(nn.Conv2d(16, 16, 3, padding=1), nn.ReLU()) for _ in range(4)])\n",
    "        self.last_layer = nn.Linear(28*28*16, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.first_layer(x)\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.reshape(-1, 28*28*16)\n",
    "        x = self.last_layer(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1/5, Loss: 0.012, Accuracy: 89.110\n",
      "Train Epoch: 2/5, Loss: 0.010, Accuracy: 97.798\n",
      "Train Epoch: 3/5, Loss: 0.009, Accuracy: 98.418\n",
      "Train Epoch: 4/5, Loss: 0.008, Accuracy: 98.782\n",
      "Train Epoch: 5/5, Loss: 0.010, Accuracy: 99.005\n",
      "Test Accuracy: 97.940\n"
     ]
    }
   ],
   "source": [
    "net = MNISTNet() #net is a model of class MNISTNet network\n",
    "\n",
    "#################\n",
    "# train net!\n",
    "import torch.optim as optim\n",
    "\n",
    "num_epochs = 5\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.5)\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    correct = 0\n",
    "    for batch_id, (data, target) in enumerate(loader):\n",
    "        # Zeroing out gradients from previous step\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass \n",
    "        output = net(data)\n",
    "        # loss calculation\n",
    "        loss = loss_fun(output, target)\n",
    "        # Backpropagation \n",
    "        loss.backward()\n",
    "        # parameter adjustments as per the loss calculation\n",
    "        optimizer.step()\n",
    "        #tracking accuracy\n",
    "        _, pred_labels = output.max(dim=1) \n",
    "        correct += (pred_labels == target).float().sum()\n",
    "    accuracy = 100 * correct / len(dataset)    \n",
    "    print('Train Epoch: {}/{}, Loss: {:.3f}, Accuracy: {:.3f}'.format(\n",
    "                epoch+1,num_epochs, loss.item(), accuracy))  \n",
    "    \n",
    "#Tesing the trained model on test set\n",
    "test_set = MNIST('data', train=False, transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=16, shuffle=False) #first load test data to \n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        output = net(data)  \n",
    "        _, pred_labels = output.max(dim=1) \n",
    "        correct += (pred_labels == target).float().sum()\n",
    "    accuracy = 100 * correct / len(test_set)    \n",
    "    print('Test Accuracy: {:.3f}'.format(accuracy))  \n",
    "#################\n",
    "\n",
    "torch.save(net.state_dict(), 'mnist_net.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #loading test set\n",
    "# test_set = MNIST('data', train=False, transform=transforms.ToTensor())\n",
    "# test_loader = DataLoader(dataset=test_set, batch_size=16, shuffle=False)\n",
    "# #evaluating the model(testing) based on the test data set\n",
    "# net.eval()\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     correct = 0\n",
    "#     for data, target in test_loader:\n",
    "#         output = net(data)  \n",
    "#         _, pred_labels = output.max(dim=1) \n",
    "#         correct += (pred_labels == target).float().sum()\n",
    "#     accuracy = 100 * correct / len(test_set)    \n",
    "#     print('Test Accuracy: {:.3f}'.format(accuracy)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR [4 bonus points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design a network architecture in ``modules.py`` and train on the CIFAR-10 data set provided by the data loader ``loader`` below. You have to get an accuracy of at least 60% on a hidden test set. Don not use any pre-defined or pre-trained network models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "from modules import CIFARNet\n",
    "\n",
    "dataset = CIFAR10('data', download=True, transform=transforms.ToTensor())\n",
    "loader = DataLoader(dataset, batch_size=16, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "<class 'tuple'>\n",
      "torch.Size([3, 32, 32])\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset)) #this is only training set\n",
    "\n",
    "el = dataset[2]                 #el is a tuple containing 2 list 1 image 2 its labels\n",
    "print(type(el))\n",
    "print(el[0].shape)                #image is again a sub list inside el so it is [1,28,28] so calling el[0][0] accesses the sblist image first then the 1st element inside the image this has now size 28x28\n",
    "print(el[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 32, 32])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "#so we have 50,000 images in the training set and dataset variable is a tuple having two lists image \n",
    "#and ther corresponding labels\n",
    "batch = iter(loader).next()   #batch is an iterator which gives a single list at a time. each list has 2 elements, element 0 is a list of 4 images and element 1 is a list of its labels\n",
    "\n",
    "data = batch[0]                     #this image is a 3D tensor => CxWxH which means image is again a list inside list\n",
    "labels = batch[1]\n",
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 400])\n"
     ]
    }
   ],
   "source": [
    "#checking flattening\n",
    "x = torch.ones(16,5,5)\n",
    "x = x.reshape(-1, 5*5*16)\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1/25, Loss: 2.308, Accuracy: 40.772\n",
      "Train Epoch: 2/25, Loss: 2.075, Accuracy: 51.994\n",
      "Train Epoch: 3/25, Loss: 1.926, Accuracy: 56.106\n",
      "Train Epoch: 4/25, Loss: 1.901, Accuracy: 58.698\n",
      "Train Epoch: 5/25, Loss: 2.127, Accuracy: 60.602\n",
      "Train Epoch: 6/25, Loss: 1.885, Accuracy: 62.200\n",
      "Train Epoch: 7/25, Loss: 1.923, Accuracy: 63.630\n",
      "Train Epoch: 8/25, Loss: 1.908, Accuracy: 64.566\n",
      "Train Epoch: 9/25, Loss: 1.515, Accuracy: 65.736\n",
      "Train Epoch: 10/25, Loss: 1.514, Accuracy: 66.612\n",
      "Train Epoch: 11/25, Loss: 1.802, Accuracy: 67.168\n",
      "Train Epoch: 12/25, Loss: 1.287, Accuracy: 67.862\n",
      "Train Epoch: 13/25, Loss: 1.395, Accuracy: 68.606\n",
      "Train Epoch: 14/25, Loss: 1.200, Accuracy: 69.170\n",
      "Train Epoch: 15/25, Loss: 1.211, Accuracy: 69.970\n",
      "Train Epoch: 16/25, Loss: 1.163, Accuracy: 70.010\n",
      "Train Epoch: 17/25, Loss: 1.660, Accuracy: 70.878\n",
      "Train Epoch: 18/25, Loss: 1.197, Accuracy: 71.092\n",
      "Train Epoch: 19/25, Loss: 1.171, Accuracy: 71.656\n",
      "Train Epoch: 20/25, Loss: 1.179, Accuracy: 71.766\n",
      "Train Epoch: 21/25, Loss: 0.929, Accuracy: 72.362\n",
      "Train Epoch: 22/25, Loss: 1.243, Accuracy: 72.760\n",
      "Train Epoch: 23/25, Loss: 0.971, Accuracy: 72.950\n",
      "Train Epoch: 24/25, Loss: 1.218, Accuracy: 73.226\n",
      "Train Epoch: 25/25, Loss: 0.907, Accuracy: 73.290\n",
      "Test Accuracy: 64.640\n"
     ]
    }
   ],
   "source": [
    "net = CIFARNet()\n",
    "\n",
    "#################\n",
    "# train net!\n",
    "import torch.optim as optim\n",
    "\n",
    "num_epochs = 25\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.003, momentum=0.9)\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    correct = 0\n",
    "    for batch_id, (data, target) in enumerate(loader):\n",
    "        # Zeroing out gradients from previous step\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass \n",
    "        output = net(data)\n",
    "        # loss calculation\n",
    "        loss = loss_fun(output, target)\n",
    "        # Backpropagation \n",
    "        loss.backward()\n",
    "        # parameter adjustments as per the loss calculation\n",
    "        optimizer.step()\n",
    "        #tracking accuracy\n",
    "        _, pred_labels = output.max(dim=1) \n",
    "        correct += (pred_labels == target).float().sum()\n",
    "    accuracy = 100 * correct / len(dataset)    \n",
    "    print('Train Epoch: {}/{}, Loss: {:.3f}, Accuracy: {:.3f}'.format(\n",
    "                epoch+1,num_epochs, loss.item(), accuracy))  \n",
    "    \n",
    "#Tesing the trained model on test set\n",
    "test_set = CIFAR10('data', train=False, transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=16, shuffle=False) #first load test data to \n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        output = net(data)  \n",
    "        _, pred_labels = output.max(dim=1) \n",
    "        correct += (pred_labels == target).float().sum()\n",
    "    accuracy = 100 * correct / len(test_set)    \n",
    "    print('Test Accuracy: {:.3f}'.format(accuracy)) \n",
    "#################\n",
    "\n",
    "torch.save(net.state_dict(), 'cifar_net.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
